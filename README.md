To do:
# for all cat variables, find best encoding, add additional encodings if needed
# for all cont variables, duplicate one and normalize + transform for non-tree models
# imputation of missing values
# grid search 
# ensemble of models
# dae / transformers 
# confusion matrix analysis, precission recall score, further sampling based on that
# manual feature engineering


Run 1:
# one hot encoding for all 
# logistic regression (without transform but with normalize)
# missing values are removed 
# no grid search 
# 5 fold stratified 
# no autoencoders 
# no use of capital-gain/ capital-loss/ education for now 
Avg f1 score : 0.661

To be updated...